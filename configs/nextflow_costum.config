/*
 * -------------------------------------------------
 *  nfcore custom profile Nextflow config file
 * -------------------------------------------------
 * Config options for all custom environments.
 * Cluster-specific config options should be saved
 * in the conf folder and imported under a profile
 * name here.
 */

/*
 * -------------------------------------------------
 *  nfcore custom profile Nextflow config file
 * -------------------------------------------------
 * Config options for all custom environments.
 * Cluster-specific config options should be saved
 * in the conf folder and imported under a profile
 * name here.
 */

//Please use a new line per include Config section to allow easier linting/parsing. Thank you.
profiles {
  abims        { includeConfig "${params.custom_config_base}/conf/abims.config" }
  aws_tower    { includeConfig "${params.custom_config_base}/conf/aws_tower.config" }
  awsbatch     { includeConfig "${params.custom_config_base}/conf/awsbatch.config" }
  bi           { includeConfig "${params.custom_config_base}/conf/bi.config" }
  bigpurple    { includeConfig "${params.custom_config_base}/conf/bigpurple.config" }
  binac        { includeConfig "${params.custom_config_base}/conf/binac.config" }
  biohpc_gen   { includeConfig "${params.custom_config_base}/conf/biohpc_gen.config" }
  cambridge    { includeConfig "${params.custom_config_base}/conf/cambridge.config" }
  cbe          { includeConfig "${params.custom_config_base}/conf/cbe.config" }
  ccga_dx      { includeConfig "${params.custom_config_base}/conf/ccga_dx.config" }
  ccga_med     { includeConfig "${params.custom_config_base}/conf/ccga_med.config" }
  cfc          { includeConfig "${params.custom_config_base}/conf/cfc.config" }
  cfc_dev      { includeConfig "${params.custom_config_base}/conf/cfc_dev.config" }
  crick        { includeConfig "${params.custom_config_base}/conf/crick.config" }
  czbiohub_aws { includeConfig "${params.custom_config_base}/conf/czbiohub_aws.config" }
  denbi_qbic   { includeConfig "${params.custom_config_base}/conf/denbi_qbic.config" }
  ebc          { includeConfig "${params.custom_config_base}/conf/ebc.config" }
  eddie        { includeConfig "${params.custom_config_base}/conf/eddie.config" }
  eva          { includeConfig "${params.custom_config_base}/conf/eva.config" }
  genotoul     { includeConfig "${params.custom_config_base}/conf/genotoul.config" }
  genouest     { includeConfig "${params.custom_config_base}/conf/genouest.config" }
  gis          { includeConfig "${params.custom_config_base}/conf/gis.config" }
  google       { includeConfig "${params.custom_config_base}/conf/google.config" }
  hebbe        { includeConfig "${params.custom_config_base}/conf/hebbe.config" }
  icr_davros   { includeConfig "${params.custom_config_base}/conf/icr_davros.config" }
  ifb_core     { includeConfig "${params.custom_config_base}/conf/ifb_core.config" }
  imperial     { includeConfig "${params.custom_config_base}/conf/imperial.config" }
  imperial_mb  { includeConfig "${params.custom_config_base}/conf/imperial_mb.config" }  
  jax          { includeConfig "${params.custom_config_base}/conf/jax.config" }
  lugh         { includeConfig "${params.custom_config_base}/conf/lugh.config" }
  mpcdf        { includeConfig "${params.custom_config_base}/conf/mpcdf.config" }
  munin        { includeConfig "${params.custom_config_base}/conf/munin.config" }
  oist         { includeConfig "${params.custom_config_base}/conf/oist.config" }
  pasteur      { includeConfig "${params.custom_config_base}/conf/pasteur.config" }
  phoenix      { includeConfig "${params.custom_config_base}/conf/phoenix.config" }
  prince       { includeConfig "${params.custom_config_base}/conf/prince.config" }
  sanger       { includeConfig "${params.custom_config_base}/conf/sanger.config"}
  seg_globe    { includeConfig "${params.custom_config_base}/conf/seg_globe.config"}
  shh          { includeConfig "${params.custom_config_base}/conf/shh.config" }
  uct_hpc      { includeConfig "${params.custom_config_base}/conf/uct_hpc.config" }
  uppmax       { includeConfig "${params.custom_config_base}/conf/uppmax.config" }
  utd_ganymede { includeConfig "${params.custom_config_base}/conf/utd_ganymede.config" }
  utd_sysbio   { includeConfig "${params.custom_config_base}/conf/utd_sysbio.config" }
  uzh          { includeConfig "${params.custom_config_base}/conf/uzh.config" }
}

// If user hostnames contain one of these substring and they are
// not running the associated profile, it will trigger a warning message
// Should be defined here for all profiles (not within profile config)
params {
  // This is a groovy map, not a nextflow parameter set
  hostnames = [
    binac: ['.binac.uni-tuebingen.de'],
    cbe: ['.cbe.vbc.ac.at'],
    cfc: ['.hpc.uni-tuebingen.de'],
    crick: ['.thecrick.org'],
    genotoul: ['.genologin1.toulouse.inra.fr', '.genologin2.toulouse.inra.fr'],
    genouest: ['.genouest.org'],
    icr_davros: ['.davros.compute.estate'],
    imperial: ['.hpc.ic.ac.uk'],
    imperial_mb: ['.hpc.ic.ac.uk'],
    uppmax: ['.uppmax.uu.se'],
    utd_ganymede: ['ganymede.utdallas.edu'],
    utd_sysbio: ['sysbio.utdallas.edu']
  ]
}

process {

  // TODO nf-core: Check the defaults for all processes
  cpus = { check_max( 1 * task.attempt, 'cpus' ) }
  memory = { check_max( 7.GB * task.attempt, 'memory' ) }
  time = { check_max( 4.h * task.attempt, 'time' ) }

  errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
  maxRetries = 5
  maxErrors = '-1'

  // Process-specific resource requirements
  // NOTE - Only one of the labels below are used in the fastqc process in the main script.
  //        If possible, it would be nice to keep the same label naming convention when
  //        adding in your processes.
  // TODO nf-core: Customise requirements for specific processes.
  // See https://www.nextflow.io/docs/latest/config.html#config-process-selectors
   
  withLabel:process_wsl {
    cpus = 6 
    memory = { check_max( 30.GB * task.attempt, 'memory' ) }
    time = { check_max( 10.h * task.attempt, 'time' ) }
    cleanup = true

  }
  
  withLabel:process_low {
    cpus = { check_max( 2 * task.attempt, 'cpus' ) }
    memory = { check_max( 14.GB * task.attempt, 'memory' ) }
    time = { check_max( 6.h * task.attempt, 'time' ) }
  }
  withLabel:process_medium {
    cpus = { check_max( 6 * task.attempt, 'cpus' ) }
    memory = { check_max( 42.GB * task.attempt, 'memory' ) }
    time = { check_max( 8.h * task.attempt, 'time' ) }
  }
  withLabel:process_high {
    cpus = { check_max( 12 * task.attempt, 'cpus' ) }
    memory = { check_max( 84.GB * task.attempt, 'memory' ) }
    time = { check_max( 10.h * task.attempt, 'time' ) }
  }
  withLabel:process_long {
    time = { check_max( 20.h * task.attempt, 'time' ) }
  }
  
  //fixing the root ownership issue in the work directory while using docker
  docker {
  fixOwnership = true
  }

}
